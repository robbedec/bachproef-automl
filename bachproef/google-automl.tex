%%=============================================================================
%% Google AutoML
%%=============================================================================

\chapter{Google Cloud AutoML}
\label{ch:google-automl}

Google Cloud AutoML is zoals de naam zegt, deel van het Cloud platform. In dit hoofdstuk wordt gebruik gemaakt van een \textit{storage server} en de \textit{vision API}. Om toegang te krijgen is uiteraard een account nodig, en als nieuwe gebruiker is er \$300 beschikbaar die vrij gespendeerd kan worden op het platform (binnen de periode van één jaar).

De \textit{vision API} is een verzameling van afbeeldings- en videoherkenning die verwerkt is in het AutoML platform. Daarnaast is er ook nog ondersteuning voor \textit{natural language processing} en andere \textit{beta} diensten. Alle mogelijkheden hebben een uitgebreide documentatie\footnote{\url{https://cloud.google.com/automl/docs?hl=nl}} die deels verwerkt werd in de literatuurstudie. De interfaces zijn zeer gebruiksvriendelijk en maken vaak gebruik van drag en drop systemen. 

Vooraleer er gestart kan worden is een korte setup op zijn plaats. De volledige code van het gebruikte \textit{jupyter notebook} is te vinden in Appendix \ref{ch:app:google-automl}.

\section{Voorafgaand werk}
\label{sec:google-automl-before}

\subsection{Google Cloud Data Storage}
\label{subsec:google-cloud-data-storage}

Om de \textit{computer vision API} te gebruiken moeten de afbeeldingen geüpload worden. Dit kan rechtstreeks in batches van max. 30 MB. Met de hoeveelheid afbeeldingen die gebruikt worden in dit onderzoek is dit niet praktisch. Voor grote hoeveelheden data kan daarom een online bucket gebruikt worden. De afbeeldingen bevinden zich dan op een \textit{data storage server} van Google Cloud.

De indeling van de data moet er als volgt uitzien:

\dirtree{%
    .1 online bucket.
    .2 cat.
    .3 cat.0.jpg.
    .3 cat.1.jpg.
    .3 cat.2.jpg.
    .2 dog.
    .3 dog.0.jpg.
    .3 dog.1.jpg.
    .3 dog.2.jpg.
}

Dit is belangrijk voor de volgende stap. Op deze manier kunnen er makkelijk labels toegekend worden aan de afbeeldingen. Dit op een manier die het platform kan interpreteren.

\subsection{Structuur van de data}
\label{subsec:google-structure}

Nu alle data online beschikbaar is, moet er nog een overzicht gecreëerd worden. Aan de hand van een \textit{jupyter notebook} wordt een csv gemaakt die voor elke afbeelding, de locatie op Google Cloud Storage en het bijhorend label bevat. Alle niet afbeeldingen worden uit de map gefiltered

\begin{python}
data_array = []

for (dict_key, files_list) in files_dict.items():
    for filename in files_list:
        if '.jpg' not in filename:
            continue # don't include non-photos
            
        label = dict_key
        data_array.append((base_gcs_path + dict_key + '/' + filename , label))

\end{python}

Nu moet \pyth{data_array} enkel nog ingeladen worden in een \textit{pandas dataframe}. In de \textit{pandas library} zit een functie die een dataframe kan opslaan als een csv bestand. Merk op dat de indexes van de kolommen en rijen niet mee opgeslagen worden. Deze kunnen als \pyth{False} geflagged worden in de functie.

\pyth{dataframe.to_csv('all_data.csv', index=False, header=False)}

De output van het csv bestand zou er als onderstaand uit moeten zien. Natuurlijk met een andere bucket naam.

gs://rdc-automl-catsvsdogs/dog/dog.100.jpg dog \\
gs://rdc-automl-catsvsdogs/dog/dog.1000.jpg dog \\
… … … \\
gs://rdc-automl-catsvsdogs/cat/cat.9995.jpg cat \\
gs://rdc-automl-catsvsdogs/cat/cat.9996.jpg cat
\\

Het csv bestand moet dan ook toegevoegd worden aan de bucket.

\section{Model trainen en evalueren}
\label{sec:google-automl-train}

Om het trainen te starten moet nu enkel het csv bestand (dat op Google Cloud Storage) staat selecteren. Vervolgens worden alle afbeeldingen geïmporteerd en opgesplitst in training, validatie en testen. In ons geval van 22500 afbeeldingen worden ze als volgt opgesplitst.

\begin{itemize}
    \item Training: 10000
    \item Validatie: 5000
    \item Testen: 2500
\end{itemize}

Elke dataset is gelijk verdeeld over de twee categorieën. Als er dus over 10000 afbeeldingen gesproken worden, zijn het in feite 5000 katten en 5000 honden.

\section{Resultaten}
\label{sec:google-automl-results}

Het model behaalt een score van 99\% en komt zo overeen met de beste inzending van de Kaggle wedstrijd. De stelling van Google, om \textit{machine learning} makkelijk en toegankelijk te maken klopt dus. Met namelijk niks van \textit{preprocessing} of dergelijke scoort het toch uitstekend.

\begin{figure}
    \centering
    \includegraphics[width=\linewidth]{img/google-automl-pred.png}
    \caption{Vier 'onduidelijke' voorspelde afbeeldingen}
    \label{fig:google-predictions}
\end{figure}

\begin{table}[ht]
    \centering
    \begin{tabular}{c c c c} % centered columns (4 columns)
        \hline\hline %inserts double horizontal lines
        Afbeelding & Voorspelling & Zekerheid & Werkelijk label \\ [0.5ex] % inserts table
        %heading
        \hline % inserts single horizontal line
        1   &  Hond  & 100\%   & Hond \\ 
        \hline %inserts single line
        2   &  Hond  & 66\%   & Hond \\ 
        \hline
        3   &  Hond  & 100\%   & Hond \\ 
        \hline
        4   &  Hond  & 97\%   & Kat \\ 
        \hline
    \end{tabular}
    \caption{Vier voorspelde afbeeldingen in Google Cloud AutoML (Figuur \ref{fig:google-predictions})}
    \label{table:google-predicted-images}
\end{table}

\begin{figure}
    \begin{subfigure}{0.5\textwidth}
        \centering
        \includegraphics[width=0.8\linewidth]{img/google-automl-performance1.png}
        \caption{}
        \label{fig:google-performance1}
    \end{subfigure}
    \begin{subfigure}{0.5\textwidth}
        \centering
        \includegraphics[width=0.8\linewidth]{img/google-automl-performance12.png}
        \caption{Confusion matrix}
        \label{fig:google-performance2}
    \end{subfigure}
    \caption{Performantie van het model}
    \label{fig:google-performance}
\end{figure}

Op de testdataset van 2500 afbeeldingen zijn er slechts negen verkeerde voorspellingen. De \textit{metrics} in afbeelding \ref{fig:google-performance} zijn wel de enigste feedback over het model. Zo is het niet mogelijk om verkeerd voorspelde afbeeldingen te filteren of de lagen van het model te bekijken.

Om het model snel zelf eens te testen, werden er vier onduidelijke foto's (figuur \ref{fig:google-predictions}) voorspeld. Dit kan in de \textit{cloud interface} voor \textit{batches} van maximaal tien afbeeldingen. De resultaten van de voorspellingen staan in tabel \ref{table:google-predicted-images}.

\section{Deployment}
\label{sec:google-automl-deployment}

Zoals besproken in sectie \ref{subsubsec:client-library} kunnen er interacties zijn via een \textit{client library}. De code kan oftewel intern in de applicatie verwerkt worden (indien de code geschreven is in Python). Een tweede manier is om de het Python script extern op te slaan en op te roepen als het nodig is.

\bigskip

\begin{python}
import sys

from google.cloud import automl_v1beta1
from google.cloud.automl_v1beta1.proto import service_pb2


# 'content' is base-64-encoded image data.
def get_prediction(content, project_id, model_id):
    prediction_client = automl_v1beta1.PredictionServiceClient()
    
    name = 'projects/{}/locations/us-central1/models/{}'.format(project_id, model_id)
    payload = {'image': {'image_bytes': content }}
    params = {}
    request = prediction_client.predict(name, payload, params)
    return request  # waits till request is returned

if __name__ == '__main__':
    file_path = sys.argv[1]
    project_id = sys.argv[2]
    model_id = sys.argv[3]

    with open(file_path, 'rb') as ff:
        content = ff.read()
    
    print get_prediction(content, project_id, model_id)
\end{python}

De functie verwacht drie argumenten. Een afbeelding (geëncodeerd in base-64), het project\_id en het model\_id. De ID's zijn te vinden in de eigenschappen van het project en model op Google Cloud.

\bigskip

\begin{python}
python predict.py YOUR_LOCAL_IMAGE_FILE 156243918112 ICN8843552342109323264
\end{python}

\begin{figure}
    \centering
    \includegraphics[width=\linewidth]{img/google-automl-rest.png}
    \caption{Requests sturen naar de REST API van Google AutoML.}
    \label{fig:google-automl-rest}
\end{figure}

Als een model gedeployed is, wordt er standaard een REST service aangemaakt. De gebruiker kiest dan zelf om een wrapper te schrijven (om een familiaire interface te maken) of om de requests met curl door te sturen, zoals op afbeelding \ref{fig:google-automl-rest}. 


\section{Requirements}
\label{sec:google-requirements}

\subsection{Functionele requirements}
\label{subsec:google-fr}

\subsubsection{Implementatie van het procesmodel}
\label{sucsubsec:google-fr-procesmodel}

Het platform gaat elke stap verwerken voor de gebruiker, het gaat hier over het overzicht van \ref{fig:proces-model.png}. Aan de hand van een drag en drop systeem wordt alles automatisch uitgevoerd. Enkel de data upload naar de cloud moet zelf gebeuren.

\subsubsection{Beschikbare metrics}
\label{sucsubsec:google-fr-metrics}

Na het trainen van het model krijgt de gebruiker een beknopt maar duidelijk overzicht. Naast het aantal afbeeldingen waarmee het model getraind en getest is, wordt ook de \textit{precision} en \textit{recall} getoond. Om deze begrippen te snappen is het belangrijk dat deze termen gekend zijn. \textit{True positives} (TP) is het aantal juiste voorspellingen, de \textit{false negatives} (FN) is het aantal voorspellingen die verkeerd geclassificeerd worden in het standpunt van één klasse. Beide worden in procent uitgedrukt.

De \textit{precision} is dan de verhouding correcte voorspellingen tegenover het totaal aantal voorspellingen van één enkele klasse.

\begin{equation}
    precision=\frac{TP}{TP+FP}
\end{equation}

\textit{Recall} is de verhouding tussen het aantal correct voorspelde afbeeldingen en het aantal afbeeldingen van die klasse die aanwezig is in de dataset.

\begin{equation}
    recall=\frac{TP}{TP+FN}
\end{equation}

Voorgaande begrippen zijn onderling verwerkt in de \textit{confusion matrix}, die ook gegenereerd wordt voor de gebruikte dataset.

\subsubsection{Batch verwerking}
\label{sucsubsec:google-fr-batch}

Het aantal gekozen \textit{nodes} van een \textit{deployment} configuratie. Elke \textit{node} kan op zich 3.2 requests per seconde uitvoeren. Deze schalen lineair, tien \textit{nodes} kunnen dan 32 afbeeldingen per seconde verwerken.

Voorspellingen kunnen ook in de Google Cloud Console gemaakt worden. De interface ondersteund een \textit{batch} van maximaal tien afbeeldingen. 

Het aantal \textit{nodes} zijn vrij te configureren. De gebruiker beslist zelf de capaciteit die het model ondersteunt. Het is perfect mogelijk om in één job 100.000 afbeeldingen door te sturen.

\subsection{Niet-functionele requirements}
\label{subsec:googlautoml-nfr} 

\subsubsection{Deployment}
\label{sucsubsec:google-nfr-deployment}

Met enkele klikken kan het volledig werken. De nodige infrastructuur wordt ook vrijgemaakt in Google Cloud. De bestaande oplossing kan makkelijk uitgebreid worden met bijvoorbeeld Redis.

\subsubsection{Performantie}
\label{sucsubsec:google-nfr-performantie}

Op de gekozen dataset wordt een vergelijkbare score behaald als de top scores van de competitie waarvoor het gebruikt werd (98\%).

\subsubsection{Kostprijs}
\label{sucsubsec:google-nfr-price}

\begin{table}[b!]
    \centering
    \begin{tabular}{||c c c||} 
        \hline
        Standard storage & Nearline storage & Coldline storage \\ [0.5ex] 
        \hline\hline
        \$0.026 & \$0.010 & \$0.007  \\ 
        \hline
    \end{tabular}
    \caption{Maandelijke kostprijs per GB}
    \label{table:google-storage-price}
\end{table}

Om de totale kostprijs te berekenen moet er toch rekening gehouden worden met een aantal zaken, merk op dat er mogelijks nog extra kosten bijkomen door nieuwe toepassingen te introduceren. In het algemeen kan de kostprijs opgedeeld worden in volgende groepen.

Het opslaan van data op Google Cloud is in drie verschillende categorieën. Eerst de standaard data, die veel gebruikt wordt en veel aangepast wordt door de gebruiker. Met Nearline bedoelt men data die af en toe gelezen wordt maar weinig veranderlijk is. Coldline wordt dan gebruikt voor data die enkele malen per kwartaal aangepast wordt, de stap naar archive is niet zo groot als het om back-ups gaat. De prijs van elke soort staat in tabel \ref{table:google-storage-price}.

Het trainen van het model wordt berekend aan de hand van het aantal \textit{node} uren. Elke \textit{node} op zich is een NVIDIA Tesla V100 GPU, die in een schakeling staan om optimaal te werken. Acht \textit{nodes} één uur laten werken staat gelijk aan acht trainingsuren. Per uur bedraagt de kost \$3.15. Een model uitbreiden door extra te laten trainen hanteert hetzelfde tarief.

De \textit{deployment} kosten hangen dan ook weer af van het aantal \textit{nodes} die actief staan. Elk uur kost \textit{\$1.25} om één \textit{node} te gebruiken, om diezelfde één maand te gebruiken kost dat \$900.

Een volledig overzicht van alle kosten binnen de \textit{vision} API is te vinden op de site van Google\footnote{\url{https://www.cloud.google.com/vision/automl/pricing}}.

\subsubsection{Verwerking}
\label{sucsubsec:google-nfr-verwerking}

Er zijn verschillende manieren om het model te verwerken in een bestaande applicatie, zoals besproken in sectie \ref{sec:deployment}. Het gedeployde model is ook beschikbaar en werkt als een REST API. Een gebruiker kan dus in principe een \textit{wrapper} bouwen die alle \textit{requests} onderschept en doorstuurt naar Google Cloud. De client library zelf kan intern in het programma gebruikt worden (indien Python) anders kan een applicatie ook \textit{requests} sturen aan de hand van een Python script. 